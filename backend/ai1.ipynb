{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import gdown\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import openai\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1dzL_SWBkBs5xrUxuGQTm04oe3USgkL9u\n",
      "To: /Users/riley/VSCode/HackBRASA/backend/bank.parquet\n",
      "100%|██████████| 1.57M/1.57M [00:00<00:00, 14.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1QK-VgSU3AxXUw330KjYFUj8S9hzKJsG6\n",
      "To: /Users/riley/VSCode/HackBRASA/backend/sales.parquet\n",
      "100%|██████████| 6.37M/6.37M [00:00<00:00, 16.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JN0bR84sgZ_o4wjKPBUmz45NeEEkVgt7\n",
      "To: /Users/riley/VSCode/HackBRASA/backend/mcc.parquet\n",
      "100%|██████████| 57.3k/57.3k [00:00<00:00, 1.64MB/s]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'bank': \"1dzL_SWBkBs5xrUxuGQTm04oe3USgkL9u\",    # banking data\n",
    "    'sales': \"1QK-VgSU3AxXUw330KjYFUj8S9hzKJsG6\",   # sales data\n",
    "    'mcc': \"1JN0bR84sgZ_o4wjKPBUmz45NeEEkVgt7\",     # mcc description\n",
    "}\n",
    "\n",
    "# Download all files from Google Drive\n",
    "for name, file_id in data.items():\n",
    "    gdown.download(f'https://drive.google.com/uc?id={file_id}', name + '.parquet', quiet=False)\n",
    "    \n",
    "# Read all files and store on a dictionary of pandas dataframes\n",
    "df = {} \n",
    "for name in data.keys():\n",
    "    df[name] = pd.read_parquet(name + '.parquet')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Functions\n",
    "def display_head_with_scroll(df, num_rows=5):\n",
    "    \"\"\"\n",
    "    Display a DataFrame with horizontal scrolling enabled.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to display.\n",
    "    num_rows (int): The number of rows to display. Default is 5.\n",
    "    \"\"\"\n",
    "    display(HTML(scrolling_css + df.head(num_rows).to_html(classes='dataframe-div')))\n",
    "\n",
    "def require(package):\n",
    "    try:\n",
    "        # Try to import the package\n",
    "        globals()[package] = __import__(package)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"{package} is not installed. Trying to install via Homebrew...\")\n",
    "        try:\n",
    "            # Attempt to install the package using Homebrew\n",
    "            subprocess.check_call([\"brew\", \"install\", package])\n",
    "            # After installation, try importing again\n",
    "            globals()[package] = __import__(package)\n",
    "            return True\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"Failed to install {package} via Homebrew. Trying pip with --break-system-packages...\")\n",
    "            try:\n",
    "                # If Homebrew fails, try installing via pip with the break-system-packages flag\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--break-system-packages\"])\n",
    "                globals()[package] = __import__(package)\n",
    "                return True\n",
    "            except ImportError:\n",
    "                print(f\"Failed to install {package}.\")\n",
    "                return False\n",
    "            \n",
    "import requests\n",
    "\n",
    "# Replace with your OpenAI API key\n",
    "\n",
    "\n",
    "# Initialize global variables\n",
    "newprompt = \"\"\n",
    "output = \"\"\n",
    "total_tokens_used = 0\n",
    "cost = 0.0\n",
    "\n",
    "def openai_prompting(prompt):\n",
    "    global newprompt\n",
    "    global output\n",
    "    global total_tokens_used\n",
    "    global cost\n",
    "    print(\"\\n\\nRunning GPT-3.5\")\n",
    "\n",
    "    # Define the endpoint URL\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "    # Set up the request headers with your API key\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "\n",
    "    # Define the request payload (input text and parameters)\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",  # choose the model\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": \"You are a data scientist with the goal of analyzing the data in response to the users prompt. The data, stored in df['sales], contains information about sales\"\n",
    "                      \" data and has been preprocessed already such that it has df['sales'].shape of (264933, 7), df['sales'].columns.tolist() of ['document_id', 'date_time', 'value', 'card_number', 'type', 'mcc', 'state'],\"\n",
    "                      \" and df['sales'].dtypes.tolist() of [dtype('int64'), dtype('<M8[us]'), dtype('float64'), dtype('O'), dtype('O'), dtype('int64'), dtype('O')]. Please make sure to return only python code that is executable\"\n",
    "                      \"for querying the data. You can use numpy or pandas to complete the task in response to the users prompt. I have attached the first row of the data as an example. The code should output the answer to the user\"\n",
    "                      \" in the simplest manner possible such as an integer with a $.\"},\n",
    "                      {\"role\": \"user\", \"content\": f\"{prompt}\"}],  # prompt here\n",
    "        \"max_tokens\": 800  # maximum number of tokens for the model\n",
    "    }\n",
    "    if prompt != \"\":\n",
    "        newprompt = prompt\n",
    "        response = requests.post(url, json=data, headers=headers)\n",
    "    else:\n",
    "        print(\"You have an empty prompt, so printing the previous prompt again or default if first prompt is empty.\\n\")\n",
    "        print(f\"Prompt: {newprompt}\")\n",
    "        print(f\"\\nOutput: {output}\")\n",
    "        print(\"\\nTokens Used: \" + str(total_tokens_used))\n",
    "        print(\"Cost: $\" + format(cost, \".8f\").rstrip(\"0\").rstrip(\".\"))\n",
    "        return\n",
    "\n",
    "    # Check if request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse response to get the text and number of tokens\n",
    "        output = response.json()['choices'][0]['message']['content']\n",
    "        output = output.strip().replace(\"\\n\\n\", \"\\n\")\n",
    "        prompt_tokens_used = response.json()['usage']['prompt_tokens']\n",
    "        completion_tokens_used = response.json()['usage']['completion_tokens']\n",
    "        total_tokens_used = response.json()['usage']['total_tokens']\n",
    "        \n",
    "        # Pricing based on gpt-3.5-turbo\n",
    "        cost_per_input_token = 0.002 / 1_000  # $0.002 per 1,000 tokens for inputs\n",
    "        cost_per_output_token = 0.002 / 1_000  # $0.002 per 1,000 tokens for outputs\n",
    "        cost = prompt_tokens_used * cost_per_input_token + completion_tokens_used * cost_per_output_token\n",
    "\n",
    "        # Print the completion text, tokens used, and cost\n",
    "        print(f\"Prompt: {newprompt}\")\n",
    "        print(f\"\\nOutput: {output}\")\n",
    "        print(\"\\nTokens Used: \" + str(total_tokens_used))\n",
    "        print(\"Cost: $\" + format(cost, \".8f\").rstrip(\"0\").rstrip(\".\"))\n",
    "        return output\n",
    "    else:\n",
    "        # Print error message if request was not successful\n",
    "        print(\"Error:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the sales data\n",
    "df['sales']['date_time'] = pd.to_datetime(df['sales']['date_time'])  # Convert to datetime\n",
    "df['sales']['day_of_week'] = df['sales']['date_time'].dt.day_name()  # Extract day of the week\n",
    "df['sales']['hour'] = df['sales']['date_time'].dt.hour              # Extract hour of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dtype('int64'),\n",
       " dtype('<M8[us]'),\n",
       " dtype('float64'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('int64'),\n",
       " dtype('O')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sales'].dtypes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(query):\n",
    "    # Check for specific day queries (e.g., \"Friday\")\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    for day in days:\n",
    "        if day.lower() in query.lower():\n",
    "            return {\"type\": \"day_query\", \"day\": day}\n",
    "    \n",
    "    # Add more parsing rules as needed for time ranges, specific dates, etc.\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_data(parsed_query):\n",
    "    if parsed_query[\"type\"] == \"day_query\":\n",
    "        day = parsed_query[\"day\"]\n",
    "        # Sum sales for the specific day of the week\n",
    "        sales = df['sales'][df['sales']['day_of_week'] == day]['value'].sum()\n",
    "        return sales\n",
    "\n",
    "    # Add more query types as needed (e.g., time-based queries)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sales on Friday: $144457633.88\n"
     ]
    }
   ],
   "source": [
    "user_query = \"How were sales on Friday?\"\n",
    "\n",
    "# Step 1: Parse the query\n",
    "parsed_query = parse_query(user_query)\n",
    "\n",
    "# Step 2: Query the sales data\n",
    "result = query_data(parsed_query)\n",
    "\n",
    "# Step 3: Display the result\n",
    "if result is not None:\n",
    "    print(f\"Total sales on {parsed_query['day']}: ${result}\")\n",
    "else:\n",
    "    print(\"No matching data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running GPT-3.5\n",
      "Prompt: Quais foram essas vendas no fim de semana de janeiro de 2023?\n",
      "\n",
      "Output: ```python\n",
      "import pandas as pd\n",
      "# Filtrando as vendas no fim de semana de janeiro de 2023\n",
      "sales_weekend_jan_2023 = df['sales'][(df['sales']['date_time'].dt.month == 1) & \n",
      "                                    (df['sales']['date_time'].dt.year == 2023) & \n",
      "                                    (df['sales']['date_time'].dt.dayofweek >= 5)]\n",
      "# Somando os valores das vendas\n",
      "total_sales_weekend_jan_2023 = sales_weekend_jan_2023['value'].sum()\n",
      "total_sales_weekend_jan_2023\n",
      "```\n",
      "\n",
      "Tokens Used: 367\n",
      "Cost: $0.000734\n",
      "Generated Prompt:\n",
      "\n",
      " ```python\n",
      "import pandas as pd\n",
      "# Filtrando as vendas no fim de semana de janeiro de 2023\n",
      "sales_weekend_jan_2023 = df['sales'][(df['sales']['date_time'].dt.month == 1) & \n",
      "                                    (df['sales']['date_time'].dt.year == 2023) & \n",
      "                                    (df['sales']['date_time'].dt.dayofweek >= 5)]\n",
      "# Somando os valores das vendas\n",
      "total_sales_weekend_jan_2023 = sales_weekend_jan_2023['value'].sum()\n",
      "total_sales_weekend_jan_2023\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Define the user query\n",
    "user_query = \"Quais foram essas vendas no fim de semana de janeiro de 2023?\"\n",
    "\n",
    "# Extract the first five rows of df['sales'] as an example to include in the prompt\n",
    "sample_data = df['sales'].head(1).to_string(index=False)\n",
    "\n",
    "# Ask the model to generate a prompt that includes the user query and lets it know about the data\n",
    "generation_prompt = f\"\"\"\n",
    "Given the following user query:\n",
    "\n",
    "'{user_query}'\n",
    "\n",
    "Please generate a prompt that includes the necessary instructions and informs the model that it will be expected to analyze the data. The data will be provided, and you can assume that the data is in a Pandas DataFrame. Below are the first five rows of the DataFrame that will be used for analysis:\n",
    "\n",
    "{sample_data}\n",
    "\n",
    "Please generate a prompt that explains what the model should do based on the user's query and the data provided.\n",
    "\"\"\"\n",
    "\n",
    "# Send the request to OpenAI to generate the prompt\n",
    "response_text = openai_prompting(user_query)\n",
    "\n",
    "# Extract the generated prompt\n",
    "print(\"Generated Prompt:\\n\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "# Filtrando as vendas no fim de semana de janeiro de 2023\n",
      "sales_weekend_jan_2023 = df['sales'][(df['sales']['date_time'].dt.month == 1) & \n",
      "                                    (df['sales']['date_time'].dt.year == 2023) & \n",
      "                                    (df['sales']['date_time'].dt.dayofweek >= 5)]\n",
      "# Somando os valores das vendas\n",
      "total_sales_weekend_jan_2023 = sales_weekend_jan_2023['value'].sum()\n",
      "total_sales_weekend_jan_2023\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3419941.52)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Filtrando as vendas no fim de semana de janeiro de 2023\n",
    "sales_weekend_jan_2023 = df['sales'][(df['sales']['date_time'].dt.month == 1) & \n",
    "                                    (df['sales']['date_time'].dt.year == 2023) & \n",
    "                                    (df['sales']['date_time'].dt.dayofweek >= 5)]\n",
    "# Somando os valores das vendas\n",
    "total_sales_weekend_jan_2023 = sales_weekend_jan_2023['value'].sum()\n",
    "total_sales_weekend_jan_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'[' was never closed (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[81], line 7\u001b[0;36m\n\u001b[0;31m    exec(line, globals(), local_vars)\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    sales_weekend_jan_2023 = df['sales'][(df['sales']['date_time'].dt.month == 1) &\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '[' was never closed\n"
     ]
    }
   ],
   "source": [
    "output = output.replace(\"```python\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "# Prepare a dictionary to capture the local variables\n",
    "local_vars = {}\n",
    "\n",
    "# Execute the code line by line\n",
    "for line in output.strip().split('\\n'):\n",
    "    exec(line, globals(), local_vars)\n",
    "\n",
    "# Print the result\n",
    "formatted_result = \"${:,.2f}\".format(local_vars['sales_afternoon_2023'])\n",
    "print(formatted_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
